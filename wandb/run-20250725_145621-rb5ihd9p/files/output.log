Train set shape: torch.Size([16000, 1, 128, 128])
Validation set shape: torch.Size([2000, 1, 128, 128])
Test set shape: torch.Size([2000, 1, 128, 128])
Epochs:   0%|          | 0/126 [00:42<?, ?it/s]
Traceback (most recent call last):
  File "/home/johnma/d-flow/train.py", line 113, in <module>
    scaler.scale(loss).backward()
  File "/home/johnma/d-flow/venv/lib64/python3.9/site-packages/torch/_tensor.py", line 648, in backward
    torch.autograd.backward(
  File "/home/johnma/d-flow/venv/lib64/python3.9/site-packages/torch/autograd/__init__.py", line 353, in backward
    _engine_run_backward(
  File "/home/johnma/d-flow/venv/lib64/python3.9/site-packages/torch/autograd/graph.py", line 824, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
  File "/home/johnma/d-flow/venv/lib64/python3.9/site-packages/torch/autograd/function.py", line 307, in apply
    return user_fn(self, *args)
  File "/home/johnma/d-flow/venv/lib64/python3.9/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 2111, in backward
    return impl_fn()
  File "/home/johnma/d-flow/venv/lib64/python3.9/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 2097, in impl_fn
    out = CompiledFunction._backward_impl(ctx, all_args)
  File "/home/johnma/d-flow/venv/lib64/python3.9/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 2217, in _backward_impl
    out = call_func_at_runtime_with_args(
  File "/home/johnma/d-flow/venv/lib64/python3.9/site-packages/torch/_functorch/_aot_autograd/utils.py", line 126, in call_func_at_runtime_with_args
    out = normalize_as_list(f(args))
  File "/home/johnma/d-flow/venv/lib64/python3.9/site-packages/torch/_dynamo/eval_frame.py", line 838, in _fn
    return fn(*args, **kwargs)
  File "/home/johnma/d-flow/venv/lib64/python3.9/site-packages/torch/_inductor/output_code.py", line 460, in __call__
    return self.current_callable(inputs)
  File "/home/johnma/d-flow/venv/lib64/python3.9/site-packages/torch/_inductor/utils.py", line 2404, in run
    return model(new_inputs)
  File "/tmp/torchinductor_johnma/44/c44dqgbkumxkcoxy6crjd6rvyucn47q7s735wac76caatb3knz35.py", line 7586, in call
    buf125 = empty_strided_cuda((128, 4096, 4096), (16777216, 1, 4096), torch.float16)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.00 GiB. GPU 0 has a total capacity of 47.37 GiB of which 167.69 MiB is free. Including non-PyTorch memory, this process has 47.20 GiB memory in use. Of the allocated memory 46.20 GiB is allocated by PyTorch, and 494.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/home/johnma/d-flow/train.py", line 113, in <module>
    scaler.scale(loss).backward()
  File "/home/johnma/d-flow/venv/lib64/python3.9/site-packages/torch/_tensor.py", line 648, in backward
    torch.autograd.backward(
  File "/home/johnma/d-flow/venv/lib64/python3.9/site-packages/torch/autograd/__init__.py", line 353, in backward
    _engine_run_backward(
  File "/home/johnma/d-flow/venv/lib64/python3.9/site-packages/torch/autograd/graph.py", line 824, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
  File "/home/johnma/d-flow/venv/lib64/python3.9/site-packages/torch/autograd/function.py", line 307, in apply
    return user_fn(self, *args)
  File "/home/johnma/d-flow/venv/lib64/python3.9/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 2111, in backward
    return impl_fn()
  File "/home/johnma/d-flow/venv/lib64/python3.9/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 2097, in impl_fn
    out = CompiledFunction._backward_impl(ctx, all_args)
  File "/home/johnma/d-flow/venv/lib64/python3.9/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 2217, in _backward_impl
    out = call_func_at_runtime_with_args(
  File "/home/johnma/d-flow/venv/lib64/python3.9/site-packages/torch/_functorch/_aot_autograd/utils.py", line 126, in call_func_at_runtime_with_args
    out = normalize_as_list(f(args))
  File "/home/johnma/d-flow/venv/lib64/python3.9/site-packages/torch/_dynamo/eval_frame.py", line 838, in _fn
    return fn(*args, **kwargs)
  File "/home/johnma/d-flow/venv/lib64/python3.9/site-packages/torch/_inductor/output_code.py", line 460, in __call__
    return self.current_callable(inputs)
  File "/home/johnma/d-flow/venv/lib64/python3.9/site-packages/torch/_inductor/utils.py", line 2404, in run
    return model(new_inputs)
  File "/tmp/torchinductor_johnma/44/c44dqgbkumxkcoxy6crjd6rvyucn47q7s735wac76caatb3knz35.py", line 7586, in call
    buf125 = empty_strided_cuda((128, 4096, 4096), (16777216, 1, 4096), torch.float16)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.00 GiB. GPU 0 has a total capacity of 47.37 GiB of which 167.69 MiB is free. Including non-PyTorch memory, this process has 47.20 GiB memory in use. Of the allocated memory 46.20 GiB is allocated by PyTorch, and 494.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
